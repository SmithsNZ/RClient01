{
    "collab_server" : "",
    "contents" : "## getSentiment(vars, ...) - Scores natural language text and creates a column that contains probabilities that the sentiments in the text are positive.\n\n# Create the data\nCustomerReviews <- data.frame(Review = c(\n  \"I really did not like the taste of it\",\n  \"It was surprisingly quite good!\",\n  \"I will never ever ever go to that place again!!\",\n  \"The council is a great place to work\",\n  \"The council is a terrible place to work\",\n  \"The council is a awful place to work\",\n  \"The council is a terrific place to work\",\n  \"I hate the council\",\n  \"I love the council\"),\n  stringsAsFactors = FALSE)\n\n\n# Get the sentiment scores\nsentimentScores <- rxFeaturize(data = CustomerReviews, # overwrite=TRUE,\n                               mlTransforms = getSentiment(vars = list(SentimentScore = \"Review\")))\n\nsentimentScores\n\n## Defining the tag column as a categorical type\ntraining_data[\"tag\"] = training_data[\"tag\"].astype(\"category\")\n\n\n# ---\n\n## Create a machine learning model for multiclass text classification. \n## We are using a text featurizer function to split the text in features of 2-word chunks\n\n#ngramLength=2: include not only \"Word1\", \"Word2\", but also \"Word1 Word2\"\n#weighting=\"TfIdf\": Term frequency & inverse document frequency\nmodel = rx_logistic_regression(formula = \"tag ~ features\", data = training_data, method = \"multiClass\", ml_transforms=[\n  featurize_text(language=\"English\",\n                 cols=dict(features=\"pr_review_content\"),\n                 word_feature_extractor=n_gram(2, weighting=\"TfIdf\"))])\n\n\n# Let's translate the score to something more meaningful\nsentimentScores$PredictedRating <- ifelse(sentimentScores$SentimentScore > 0.6, \n                                          \"AWESOMENESS\", \"BLAH\")\n\n# Let's look at the results\nsentimentScores\n\n###########################################################################################\n\nlibrary(readr)\n\n#download data\ndownload.file(\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", destfile = \"aclImdb_v1.tar.gz\")\nuntar(\"aclImdb_v1.tar.gz\") #this can take a few minutes\n\n#prepare data\nset.seed(1)\nfnames=list.files(\"aclImdb\", pattern = \"[[:digit:]_]+.txt\", recursive = TRUE, full.names = TRUE)\nfnames=grep(pattern = 'unsup', fnames, invert = TRUE, value = TRUE)\nfnames=fnames[sample(length(fnames))]\n\ngetIntSentiment <- function(fname) {\n  tname=unlist(strsplit(fname, \"[.]\"))[1]\n  as.integer(unlist(strsplit(tname, \"_\"))[2])\n}\n\ndf=data.frame(fname=fnames, review = sapply(fnames, read_file),\n              sentiment= sapply(fnames, getIntSentiment)>5, stringsAsFactors = FALSE)\n\n#train, validation, test split\ntrainxdf=RxXdfData('train.xdf')\nvalidationxdf=RxXdfData('validation.xdf')\ntestxdf=RxXdfData('test.xdf')\ntrainInd=grep(pattern=\"train\", fnames, value=FALSE)\nvalidationInd=c(1:50000)[-trainInd][1:12500]\ntestInd=c(1:50000)[-trainInd][-(1:12500)]\n\n#save sentiment from the pre-trained model as a feature\nrxFeaturize(data=df[trainInd,], outData = trainxdf,\n            mlTransforms = list(getSentiment(vars = c(preSentiment=\"review\"))),\n            overwrite = TRUE, randomSeed = 1)\nrxFeaturize(data=df[validationInd,], outData = validationxdf,\n            mlTransforms = list(getSentiment(vars = c(preSentiment=\"review\"))),\n            overwrite = TRUE, randomSeed = 1)\nrxFeaturize(data=df[testInd,], outData = testxdf,\n            mlTransforms = list(getSentiment(vars = c(preSentiment=\"review\"))),\n            overwrite = TRUE, randomSeed = 1)\n#rm(df)\n\n#train models\nform1=sentiment~reviewTran\nform2=sentiment~reviewTran+preSentiment\nft=list(featurizeText(vars=c(reviewTran=\"review\"), language = \"English\",\n                      stopwordsRemover = stopwordsDefault(),\n                      case = \"lower\", keepDiacritics = FALSE, keepPunctuations = FALSE,\n                      keepNumbers = TRUE, dictionary = NULL,\n                      wordFeatureExtractor = ngramCount(), charFeatureExtractor = NULL,\n                      vectorNormalizer = \"l2\"))\nrm(list=ls(pattern = 'model\\\\.')) #make sure no other variable names match pattern = 'modelr\\\\.'\nmodel.rxlr1=rxLogisticRegression(form1, trainxdf, type='binary', mlTransforms = ft)\nmodel.rxlr2=rxLogisticRegression(form2, trainxdf, type='binary', mlTransforms = ft)\nmodel.rxff1=rxFastForest(form1, trainxdf, type = 'binary', mlTransforms = ft, randomSeed = 1)\nmodel.rxff2=rxFastForest(form2, trainxdf, type = 'binary', mlTransforms = ft, randomSeed = 1)\n\n#performance on validation set\nscores = rxImport(validationxdf, overwrite = TRUE)\nfor (modelname in ls(pattern = 'model\\\\.')) {\n  model=get(modelname)\n  scores = rxPredict(model, scores, extraVarsToWrite =  names(scores), overwrite = TRUE,\n                     suffix = paste(' ', model$Description, model$params$Formula, sep='.'))\n}\nrxRocCurve(\"sentiment\", grep(\"Probability\", names(scores), value=TRUE), scores)\n\n#performance on test set\nscores = rxImport(testxdf, overwrite = TRUE)\nfor (modelname in ls(pattern = 'model\\\\.')) {\n  model=get(modelname)\n  scores = rxPredict(model, scores, extraVarsToWrite =  names(scores), overwrite = TRUE,\n                     suffix = paste(' ', model$Description, model$params$Formula, sep='.'))\n}\nrxRocCurve(\"sentiment\", grep(\"Probability\", names(scores), value=TRUE), scores)",
    "created" : 1517530553482.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3436735532",
    "id" : "11C52C30",
    "lastKnownWriteTime" : 1517532597,
    "last_content_update" : 1517976297960,
    "path" : "C:/Bob/Source/RClient01/SentimentAnalysis01.R",
    "project_path" : "SentimentAnalysis01.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}